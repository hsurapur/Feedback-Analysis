{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vzCDWkUrhv4"
      },
      "source": [
        "## End to end Deep Learning Project Using GRU RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZAr1P5k1rhv5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout, Embedding, Input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHI1c2DN68QE",
        "outputId": "a5868c31-9f62-4fbf-e708-a4e8163ee725"
      },
      "outputs": [],
      "source": [
        "def load_stopwords(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        stopwords = file.read().splitlines()\n",
        "    return set(stopwords)\n",
        "\n",
        "stopwords = load_stopwords('english_stopwords.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ySESCiTG68QE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('data.csv', encoding='latin-1', header=None)\n",
        "df.columns = ['polarity', 'id', 'date', 'query', 'user', 'tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df[['polarity', 'tweet']]\n",
        "df['polarity'] = df['polarity'].map({0: 0, 4: 1}) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1600000, 2)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_samples = 20000\n",
        "\n",
        "class_counts = df['polarity'].value_counts()\n",
        "min_class_count = class_counts.min() \n",
        "samples_per_class = total_samples // 2 \n",
        "samples_per_class = min(samples_per_class, min_class_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "polarity\n",
            "1    10000\n",
            "0    10000\n",
            "Name: count, dtype: int64\n",
            "Total samples in balanced subset: 20000\n"
          ]
        }
      ],
      "source": [
        "balanced_df = pd.concat([\n",
        "    df[df['polarity'] == 0].sample(samples_per_class, random_state=42),\n",
        "    df[df['polarity'] == 1].sample(samples_per_class, random_state=42)\n",
        "])\n",
        "\n",
        "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "print(balanced_df['polarity'].value_counts())\n",
        "print(f\"Total samples in balanced subset: {len(balanced_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Handle negations more effectively\n",
        "    negations = [\"not\", \"no\", \"never\", \"none\", \"n't\"]\n",
        "    words = text.split()\n",
        "    \n",
        "    # Create a flag to indicate if the current word is negated\n",
        "    negation_flag = False\n",
        "    processed_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if word in negations:\n",
        "            negation_flag = True\n",
        "        else:\n",
        "            if negation_flag:\n",
        "                processed_words.append(\"not_\" + word)  # Prefix 'not_' to the word\n",
        "                negation_flag = False  # Reset the flag after the first word\n",
        "            else:\n",
        "                processed_words.append(word)\n",
        "\n",
        "    text = ' '.join(processed_words)\n",
        "\n",
        "    # Remove URLs, mentions, hashtags, punctuation, and numbers\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'#', '', text)\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stopwords]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "balanced_df['tweet'] = balanced_df['tweet'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum tweet length: 25\n"
          ]
        }
      ],
      "source": [
        "max_length = balanced_df['tweet'].apply(lambda x: len(x.split())).max()\n",
        "print(\"Maximum tweet length:\", max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_size = 10000\n",
        "dimensions = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e23o2oU268QF"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(balanced_df['tweet'], balanced_df['polarity'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ySUeImOPCf5M"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "sUIZza3U68QG"
      },
      "outputs": [],
      "source": [
        "with open('tokenizer.pkl', 'wb') as file:\n",
        "    pickle.dump(tokenizer, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-uQXA0DxBveW"
      },
      "outputs": [],
      "source": [
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length, padding='pre')\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_length, padding='pre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Afn6jN8m68QG"
      },
      "outputs": [],
      "source": [
        "num_classes = 2\n",
        "y_train_encoded = to_categorical(y_train, num_classes)\n",
        "y_test_encoded = to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eT9JsjDW68QG"
      },
      "outputs": [],
      "source": [
        "def load_glove_embeddings(file_path):\n",
        "    embeddings_index = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    return embeddings_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MrnrxKcq68QH"
      },
      "outputs": [],
      "source": [
        "def create_embedding_matrix(embeddings_index, tokenizer):\n",
        "    embedding_matrix = np.zeros((vocab_size, dimensions))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        if i < vocab_size:\n",
        "            embedding_vector = embeddings_index.get(word)\n",
        "            if embedding_vector is not None:\n",
        "                embedding_matrix[i] = embedding_vector\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "476gQYN668QH"
      },
      "outputs": [],
      "source": [
        "glove_file_path = 'glove.6B.50d.txt'\n",
        "embeddings_index = load_glove_embeddings(glove_file_path)\n",
        "embedding_matrix = create_embedding_matrix(embeddings_index, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "O8iuI_Uzrhv7",
        "outputId": "98eb4500-9e30-4480-acb9-1f15c791283c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda11\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │       <span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">90,900</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">75,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">202</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │       \u001b[38;5;34m500,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │        \u001b[38;5;34m90,900\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m75,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m202\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">666,702</span> (2.54 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m666,702\u001b[0m (2.54 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">166,702</span> (651.18 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m166,702\u001b[0m (651.18 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,000</span> (1.91 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m500,000\u001b[0m (1.91 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(max_length,)))\n",
        "model.add(Embedding(vocab_size, dimensions, weights=[embedding_matrix], trainable=False, input_length=max_length))\n",
        "model.add(GRU(150, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GRU(100))\n",
        "model.add(Dense(num_classes, activation=\"softmax\")) \n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIq8G3tdrhv7",
        "outputId": "6e3d5092-772a-4e2f-d94e-2c339d1b1f57"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.early_stopping.EarlyStopping at 0x2910926aa80>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Create an instance of EarlyStoppping Callback\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlystopping=EarlyStopping(monitor='val_loss',patience=8,restore_best_weights=True)\n",
        "earlystopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1PdWppGrhv7",
        "outputId": "be85d490-edf1-448a-b987-18934872e261"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.6329 - loss: 0.6446 - val_accuracy: 0.6794 - val_loss: 0.5976\n",
            "Epoch 2/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 97ms/step - accuracy: 0.6791 - loss: 0.5910 - val_accuracy: 0.6894 - val_loss: 0.5752\n",
            "Epoch 3/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 78ms/step - accuracy: 0.6928 - loss: 0.5714 - val_accuracy: 0.7056 - val_loss: 0.5619\n",
            "Epoch 4/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 75ms/step - accuracy: 0.7117 - loss: 0.5486 - val_accuracy: 0.7109 - val_loss: 0.5592\n",
            "Epoch 5/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 74ms/step - accuracy: 0.7363 - loss: 0.5162 - val_accuracy: 0.7081 - val_loss: 0.5600\n",
            "Epoch 6/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 75ms/step - accuracy: 0.7681 - loss: 0.4732 - val_accuracy: 0.7097 - val_loss: 0.5642\n",
            "Epoch 7/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 80ms/step - accuracy: 0.7872 - loss: 0.4434 - val_accuracy: 0.7069 - val_loss: 0.6024\n",
            "Epoch 8/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 90ms/step - accuracy: 0.8178 - loss: 0.3905 - val_accuracy: 0.6963 - val_loss: 0.6046\n",
            "Epoch 9/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 70ms/step - accuracy: 0.8471 - loss: 0.3369 - val_accuracy: 0.6975 - val_loss: 0.6883\n",
            "Epoch 10/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 93ms/step - accuracy: 0.8801 - loss: 0.2735 - val_accuracy: 0.6888 - val_loss: 0.7506\n",
            "Epoch 11/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 76ms/step - accuracy: 0.9026 - loss: 0.2276 - val_accuracy: 0.6925 - val_loss: 0.8265\n",
            "Epoch 12/20\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 75ms/step - accuracy: 0.9233 - loss: 0.1806 - val_accuracy: 0.6797 - val_loss: 0.9421\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x29111b3eb10>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train_padded, y_train_encoded, validation_split=0.2, epochs=20, callbacks=[earlystopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "e1KCnLunrhv7"
      },
      "outputs": [],
      "source": [
        "## Save model file\n",
        "model.save('gru_rnn.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZ3nXGE468QI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
